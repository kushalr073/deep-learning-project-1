{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0b28e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (1.26.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.1.2-cp310-cp310-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ---------------------------------------- 0.0/341.8 kB ? eta -:--:--\n",
      "     --------- ----------------------------- 81.9/341.8 kB 4.8 MB/s eta 0:00:01\n",
      "     --------------------- ---------------- 194.6/341.8 kB 3.0 MB/s eta 0:00:01\n",
      "     --------------------- ---------------- 194.6/341.8 kB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------- ------ 286.7/341.8 kB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------  337.9/341.8 kB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 341.8/341.8 kB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.1.2-cp310-cp310-win_amd64.whl (10.7 MB)\n",
      "   ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/10.7 MB 3.5 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.4/10.7 MB 4.9 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.7/10.7 MB 5.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/10.7 MB 5.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.3/10.7 MB 5.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.6/10.7 MB 5.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.9/10.7 MB 6.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/10.7 MB 6.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.3/10.7 MB 6.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.5/10.7 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.7/10.7 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.8/10.7 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.0/10.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/10.7 MB 4.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.2/10.7 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.3/10.7 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.4/10.7 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.6/10.7 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.7/10.7 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.8/10.7 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.9/10.7 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.1/10.7 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/10.7 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.3/10.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.5/10.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.6/10.7 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.7/10.7 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.9/10.7 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.0/10.7 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.1/10.7 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.3/10.7 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.4/10.7 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.6/10.7 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.7/10.7 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.9/10.7 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.1/10.7 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.2/10.7 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.4/10.7 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.6/10.7 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.7/10.7 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.9/10.7 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.0/10.7 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.2/10.7 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.4/10.7 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.6/10.7 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.7/10.7 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.9/10.7 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.1/10.7 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.3/10.7 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.4/10.7 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.6/10.7 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.8/10.7 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.0/10.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.2/10.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.4/10.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.6/10.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.9/10.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.1/10.7 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.4/10.7 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.7 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/10.7 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.7/10.7 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "   ---------------------------------------- 0.0/502.5 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 286.7/502.5 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  501.8/502.5 kB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 502.5/502.5 kB 4.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.1.2 pytz-2023.3.post1 tzdata-2023.3\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.2-cp310-cp310-win_amd64.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/9.3 MB 1.1 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 0.1/9.3 MB 1.1 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.2/9.3 MB 1.0 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.2/9.3 MB 1.0 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.3/9.3 MB 930.9 kB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.3/9.3 MB 930.9 kB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/9.3 MB 916.6 kB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/9.3 MB 916.6 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.5/9.3 MB 921.6 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.5/9.3 MB 921.6 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.5/9.3 MB 879.2 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.6/9.3 MB 889.7 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.6/9.3 MB 889.7 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.6/9.3 MB 868.8 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.6/9.3 MB 868.8 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.7/9.3 MB 889.4 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.8/9.3 MB 901.1 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.8/9.3 MB 901.1 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.8/9.3 MB 901.1 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.9/9.3 MB 876.9 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.9/9.3 MB 876.9 kB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.0/9.3 MB 873.8 kB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.0/9.3 MB 888.5 kB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.0/9.3 MB 888.5 kB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.1/9.3 MB 887.2 kB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.1/9.3 MB 850.1 kB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.2/9.3 MB 914.3 kB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.2/9.3 MB 914.3 kB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.4/9.3 MB 929.6 kB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.4/9.3 MB 944.7 kB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.5/9.3 MB 949.1 kB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.5/9.3 MB 963.6 kB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.6/9.3 MB 973.5 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.6/9.3 MB 970.6 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.7/9.3 MB 985.6 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.8/9.3 MB 1.0 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 1.9/9.3 MB 1.0 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 1.9/9.3 MB 1.0 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 2.0/9.3 MB 1.0 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 2.1/9.3 MB 1.0 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.2/9.3 MB 1.1 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.2/9.3 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.3/9.3 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.4/9.3 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.5/9.3 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.6/9.3 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.7/9.3 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.8/9.3 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 2.8/9.3 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.0/9.3 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.1/9.3 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.2/9.3 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.3/9.3 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.4/9.3 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.5/9.3 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.6/9.3 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.7/9.3 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.8/9.3 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.0/9.3 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 4.1/9.3 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.2/9.3 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.3/9.3 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 4.5/9.3 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 4.6/9.3 MB 1.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 4.7/9.3 MB 1.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.9/9.3 MB 1.5 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.0/9.3 MB 1.5 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.2/9.3 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.4/9.3 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.7/9.3 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 5.9/9.3 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.1/9.3 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.3/9.3 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.5/9.3 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.7/9.3 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.0/9.3 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.2/9.3 MB 1.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.4/9.3 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.7/9.3 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.9/9.3 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.3 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.3 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.7/9.3 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.0/9.3 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.3 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 2.2 MB/s eta 0:00:00\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036eeb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from seaborn) (1.26.0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from seaborn) (2.1.2)\n",
      "Collecting matplotlib!=3.6.1,>=3.3 (from seaborn)\n",
      "  Downloading matplotlib-3.8.1-cp310-cp310-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.3->seaborn)\n",
      "  Downloading contourpy-1.2.0-cp310-cp310-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.3->seaborn)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.3->seaborn)\n",
      "  Downloading fonttools-4.44.0-cp310-cp310-win_amd64.whl.metadata (156 kB)\n",
      "     ---------------------------------------- 0.0/156.8 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 30.7/156.8 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 30.7/156.8 kB ? eta -:--:--\n",
      "     --------------------------- ---------- 112.6/156.8 kB 1.1 MB/s eta 0:00:01\n",
      "     --------------------------- ---------- 112.6/156.8 kB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ 156.8/156.8 kB 721.8 kB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.3->seaborn)\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.1)\n",
      "Collecting pillow>=8 (from matplotlib!=3.6.1,>=3.3->seaborn)\n",
      "  Downloading Pillow-10.1.0-cp310-cp310-win_amd64.whl.metadata (9.6 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.3->seaborn)\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "Using cached seaborn-0.13.0-py3-none-any.whl (294 kB)\n",
      "Downloading matplotlib-3.8.1-cp310-cp310-win_amd64.whl (7.6 MB)\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/7.6 MB 5.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.6/7.6 MB 5.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.4/7.6 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.0/7.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.1/7.6 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.3/7.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.6/7.6 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.7/7.6 MB 7.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.9/7.6 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.1/7.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.3/7.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.4/7.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.6/7.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.7/7.6 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.8/7.6 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.1/7.6 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.4/7.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.5/7.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.6/7.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.8/7.6 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.1/7.6 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.2/7.6 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.3/7.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.4/7.6 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.5/7.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.7/7.6 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.8/7.6 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.0/7.6 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.1/7.6 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.2/7.6 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.3/7.6 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.3/7.6 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.4/7.6 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.5/7.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.5/7.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.6/7.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.6/7.6 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.7/7.6 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.7/7.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.8/7.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.8/7.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.9/7.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.0/7.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.1/7.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.1/7.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.2/7.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.2/7.6 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.3/7.6 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.4/7.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.5/7.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.6/7.6 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.2.0-cp310-cp310-win_amd64.whl (186 kB)\n",
      "   ---------------------------------------- 0.0/186.7 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 71.7/186.7 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  184.3/186.7 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 186.7/186.7 kB 1.9 MB/s eta 0:00:00\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.44.0-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.1 MB 2.2 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.2/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.4/2.1 MB 1.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.5/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.6/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.1/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.5/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.1 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.9/2.1 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.5-cp310-cp310-win_amd64.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.1/56.1 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading Pillow-10.1.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.6 MB 3.3 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.2/2.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.4/2.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.5/2.6 MB 3.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.6/2.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.8/2.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.9/2.6 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.0/2.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.2/2.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.6 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.4/2.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.6/2.6 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.7/2.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.9/2.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.0/2.6 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.2/2.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.3/2.6 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.5/2.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 2.9 MB/s eta 0:00:00\n",
      "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.44.0 kiwisolver-1.4.5 matplotlib-3.8.1 pillow-10.1.0 pyparsing-3.1.1 seaborn-0.13.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kushal\\.conda\\envs\\tf\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "549e5f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be7fffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\kushal\\Desktop\\FINAL_TF2_FILES\\TF_2_Notebooks_and_Data\\DATA\\fake_reg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b2a3c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "70c8a4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461.527929</td>\n",
       "      <td>999.787558</td>\n",
       "      <td>999.766096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>548.130011</td>\n",
       "      <td>998.861615</td>\n",
       "      <td>1001.042403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>410.297162</td>\n",
       "      <td>1000.070267</td>\n",
       "      <td>998.844015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>540.382220</td>\n",
       "      <td>999.952251</td>\n",
       "      <td>1000.440940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>546.024553</td>\n",
       "      <td>1000.446011</td>\n",
       "      <td>1000.338531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>476.526078</td>\n",
       "      <td>1000.018988</td>\n",
       "      <td>999.672732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>457.313186</td>\n",
       "      <td>998.855379</td>\n",
       "      <td>1000.020026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>456.720992</td>\n",
       "      <td>1001.451646</td>\n",
       "      <td>998.847606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>403.315576</td>\n",
       "      <td>1000.771023</td>\n",
       "      <td>998.562851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>599.367093</td>\n",
       "      <td>999.232244</td>\n",
       "      <td>1001.451407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          price     feature1     feature2\n",
       "0    461.527929   999.787558   999.766096\n",
       "1    548.130011   998.861615  1001.042403\n",
       "2    410.297162  1000.070267   998.844015\n",
       "3    540.382220   999.952251  1000.440940\n",
       "4    546.024553  1000.446011  1000.338531\n",
       "..          ...          ...          ...\n",
       "995  476.526078  1000.018988   999.672732\n",
       "996  457.313186   998.855379  1000.020026\n",
       "997  456.720992  1001.451646   998.847606\n",
       "998  403.315576  1000.771023   998.562851\n",
       "999  599.367093   999.232244  1001.451407\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3b0fb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price       1.000000\n",
       "feature2    0.907576\n",
       "feature1    0.444190\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "111d2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pandas to Numpy for Keras\n",
    "\n",
    "# Features\n",
    "X = df[['feature1','feature2']].values\n",
    "X\n",
    "# Label\n",
    "y = df['price'].values\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39ef68fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1e76efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "afdc8aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74046017, 0.32583248],\n",
       "       [0.43166001, 0.2555088 ],\n",
       "       [0.18468554, 0.70500664],\n",
       "       ...,\n",
       "       [0.54913363, 0.79933822],\n",
       "       [0.2834197 , 0.38818708],\n",
       "       [0.56282703, 0.42371827]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e08a3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32500a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=2),\n",
    "    Dense(units=2),\n",
    "    Dense(units=2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4f6cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Dense(2))\n",
    "model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "849bde65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(units=4,activation='relu'))\n",
    "model.add(Dense(units=4,activation='relu'))\n",
    "model.add(Dense(units=4,activation='relu'))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1790757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4899d388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "22/22 [==============================] - 1s 2ms/step - loss: 256713.5156\n",
      "Epoch 2/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256689.2344\n",
      "Epoch 3/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256667.2188\n",
      "Epoch 4/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256645.3438\n",
      "Epoch 5/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256623.4531\n",
      "Epoch 6/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256601.4844\n",
      "Epoch 7/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256579.6875\n",
      "Epoch 8/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256557.7188\n",
      "Epoch 9/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256535.8125\n",
      "Epoch 10/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256513.9844\n",
      "Epoch 11/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256492.1406\n",
      "Epoch 12/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256470.2812\n",
      "Epoch 13/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256448.3125\n",
      "Epoch 14/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 256426.4219\n",
      "Epoch 15/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256404.5938\n",
      "Epoch 16/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256382.7188\n",
      "Epoch 17/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256360.7344\n",
      "Epoch 18/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256338.9531\n",
      "Epoch 19/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256317.0469\n",
      "Epoch 20/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256295.1250\n",
      "Epoch 21/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256273.2344\n",
      "Epoch 22/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256251.3906\n",
      "Epoch 23/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256229.5156\n",
      "Epoch 24/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256207.6875\n",
      "Epoch 25/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256185.7812\n",
      "Epoch 26/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256163.8594\n",
      "Epoch 27/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256141.9375\n",
      "Epoch 28/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256120.2031\n",
      "Epoch 29/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 256098.2812\n",
      "Epoch 30/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256076.4531\n",
      "Epoch 31/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256054.5625\n",
      "Epoch 32/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256032.7500\n",
      "Epoch 33/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 256010.8125\n",
      "Epoch 34/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255988.9219\n",
      "Epoch 35/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255967.1250\n",
      "Epoch 36/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255945.2500\n",
      "Epoch 37/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255923.3594\n",
      "Epoch 38/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255901.5469\n",
      "Epoch 39/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255879.6562\n",
      "Epoch 40/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255857.8125\n",
      "Epoch 41/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255835.9375\n",
      "Epoch 42/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255814.0625\n",
      "Epoch 43/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255792.2031\n",
      "Epoch 44/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255770.3281\n",
      "Epoch 45/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255748.5781\n",
      "Epoch 46/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255726.7031\n",
      "Epoch 47/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255704.8281\n",
      "Epoch 48/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255682.9531\n",
      "Epoch 49/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255661.0938\n",
      "Epoch 50/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255639.3438\n",
      "Epoch 51/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255617.4219\n",
      "Epoch 52/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255595.5469\n",
      "Epoch 53/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255573.6875\n",
      "Epoch 54/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255551.9062\n",
      "Epoch 55/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255530.0312\n",
      "Epoch 56/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255508.1562\n",
      "Epoch 57/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255486.3281\n",
      "Epoch 58/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255464.5000\n",
      "Epoch 59/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255442.6250\n",
      "Epoch 60/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255420.7812\n",
      "Epoch 61/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255399.0469\n",
      "Epoch 62/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255377.1250\n",
      "Epoch 63/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255355.3594\n",
      "Epoch 64/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 255333.5156\n",
      "Epoch 65/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255311.6406\n",
      "Epoch 66/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255289.8281\n",
      "Epoch 67/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 255268.0000\n",
      "Epoch 68/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255246.0781\n",
      "Epoch 69/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255224.2969\n",
      "Epoch 70/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255202.4531\n",
      "Epoch 71/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255180.6562\n",
      "Epoch 72/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255158.8125\n",
      "Epoch 73/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 255136.9219\n",
      "Epoch 74/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 255115.1719\n",
      "Epoch 75/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 255093.3438\n",
      "Epoch 76/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 255071.5000\n",
      "Epoch 77/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 255049.7656\n",
      "Epoch 78/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 255027.9531\n",
      "Epoch 79/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 255006.0781\n",
      "Epoch 80/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254984.2031\n",
      "Epoch 81/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254962.4688\n",
      "Epoch 82/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254940.7344\n",
      "Epoch 83/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254918.8281\n",
      "Epoch 84/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254896.9531\n",
      "Epoch 85/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254875.2031\n",
      "Epoch 86/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254853.3438\n",
      "Epoch 87/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254831.5625\n",
      "Epoch 88/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254809.8125\n",
      "Epoch 89/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254787.9062\n",
      "Epoch 90/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254766.1719\n",
      "Epoch 91/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254744.3438\n",
      "Epoch 92/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254722.5312\n",
      "Epoch 93/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254700.7969\n",
      "Epoch 94/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254678.9688\n",
      "Epoch 95/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254657.0938\n",
      "Epoch 96/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 254635.2969\n",
      "Epoch 97/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254613.4688\n",
      "Epoch 98/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254591.7188\n",
      "Epoch 99/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254569.9688\n",
      "Epoch 100/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254548.2031\n",
      "Epoch 101/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254526.3281\n",
      "Epoch 102/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254504.5312\n",
      "Epoch 103/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254482.7031\n",
      "Epoch 104/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254460.8906\n",
      "Epoch 105/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254439.1250\n",
      "Epoch 106/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254417.2812\n",
      "Epoch 107/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254395.4219\n",
      "Epoch 108/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254373.6875\n",
      "Epoch 109/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254351.9375\n",
      "Epoch 110/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254330.1094\n",
      "Epoch 111/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254308.3125\n",
      "Epoch 112/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254286.5156\n",
      "Epoch 113/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254264.7969\n",
      "Epoch 114/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254242.9688\n",
      "Epoch 115/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254221.2500\n",
      "Epoch 116/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254199.4062\n",
      "Epoch 117/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254177.5938\n",
      "Epoch 118/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254155.8438\n",
      "Epoch 119/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254134.0781\n",
      "Epoch 120/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254112.2969\n",
      "Epoch 121/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254090.5156\n",
      "Epoch 122/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254068.7500\n",
      "Epoch 123/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254046.9688\n",
      "Epoch 124/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 254025.2188\n",
      "Epoch 125/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 254003.4219\n",
      "Epoch 126/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253981.6875\n",
      "Epoch 127/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253959.9531\n",
      "Epoch 128/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253938.0781\n",
      "Epoch 129/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253916.2969\n",
      "Epoch 130/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253894.5625\n",
      "Epoch 131/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253872.7500\n",
      "Epoch 132/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 253851.0000\n",
      "Epoch 133/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253829.2344\n",
      "Epoch 134/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253807.4219\n",
      "Epoch 135/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253785.7344\n",
      "Epoch 136/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253763.9844\n",
      "Epoch 137/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 253742.1875\n",
      "Epoch 138/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 253720.4375\n",
      "Epoch 139/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253698.6562\n",
      "Epoch 140/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253676.8438\n",
      "Epoch 141/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253655.0781\n",
      "Epoch 142/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253633.3438\n",
      "Epoch 143/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253611.6094\n",
      "Epoch 144/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253589.8281\n",
      "Epoch 145/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 253568.0625\n",
      "Epoch 146/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253546.3281\n",
      "Epoch 147/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253524.6406\n",
      "Epoch 148/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253502.8594\n",
      "Epoch 149/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253481.0938\n",
      "Epoch 150/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253459.2500\n",
      "Epoch 151/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253437.5312\n",
      "Epoch 152/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253415.8906\n",
      "Epoch 153/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253394.0625\n",
      "Epoch 154/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253372.3125\n",
      "Epoch 155/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253350.5781\n",
      "Epoch 156/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253328.8438\n",
      "Epoch 157/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253307.0469\n",
      "Epoch 158/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253285.2969\n",
      "Epoch 159/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253263.5469\n",
      "Epoch 160/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253241.8125\n",
      "Epoch 161/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 253220.0938\n",
      "Epoch 162/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253198.3125\n",
      "Epoch 163/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253176.5938\n",
      "Epoch 164/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253154.8594\n",
      "Epoch 165/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 253133.1250\n",
      "Epoch 166/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253111.3594\n",
      "Epoch 167/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253089.6406\n",
      "Epoch 168/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253067.9062\n",
      "Epoch 169/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 253046.1719\n",
      "Epoch 170/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253024.5000\n",
      "Epoch 171/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253002.7031\n",
      "Epoch 172/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252980.9531\n",
      "Epoch 173/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252959.2188\n",
      "Epoch 174/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252937.4688\n",
      "Epoch 175/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252915.7969\n",
      "Epoch 176/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252894.0312\n",
      "Epoch 177/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252872.2969\n",
      "Epoch 178/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252850.5625\n",
      "Epoch 179/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252828.8906\n",
      "Epoch 180/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252807.1562\n",
      "Epoch 181/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252785.3438\n",
      "Epoch 182/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252763.6875\n",
      "Epoch 183/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252741.9375\n",
      "Epoch 184/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252720.2969\n",
      "Epoch 185/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252698.5781\n",
      "Epoch 186/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252676.8750\n",
      "Epoch 187/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252655.1250\n",
      "Epoch 188/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252633.3906\n",
      "Epoch 189/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252611.7031\n",
      "Epoch 190/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step - loss: 252590.0312\n",
      "Epoch 191/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252568.2812\n",
      "Epoch 192/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252546.6250\n",
      "Epoch 193/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252524.8906\n",
      "Epoch 194/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252503.1250\n",
      "Epoch 195/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252481.3750\n",
      "Epoch 196/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252459.7188\n",
      "Epoch 197/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252437.9844\n",
      "Epoch 198/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252416.2969\n",
      "Epoch 199/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252394.7031\n",
      "Epoch 200/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252372.9375\n",
      "Epoch 201/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252351.2188\n",
      "Epoch 202/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252329.5312\n",
      "Epoch 203/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252307.7969\n",
      "Epoch 204/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252286.1094\n",
      "Epoch 205/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252264.4062\n",
      "Epoch 206/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252242.7188\n",
      "Epoch 207/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252220.9844\n",
      "Epoch 208/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252199.2969\n",
      "Epoch 209/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252177.6406\n",
      "Epoch 210/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252155.9375\n",
      "Epoch 211/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 252134.2344\n",
      "Epoch 212/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252112.5469\n",
      "Epoch 213/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252090.8594\n",
      "Epoch 214/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252069.1719\n",
      "Epoch 215/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252047.5000\n",
      "Epoch 216/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252025.8438\n",
      "Epoch 217/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 252004.1406\n",
      "Epoch 218/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251982.4688\n",
      "Epoch 219/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 251960.7500\n",
      "Epoch 220/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 251938.9688\n",
      "Epoch 221/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 251917.3438\n",
      "Epoch 222/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251895.6875\n",
      "Epoch 223/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251873.9844\n",
      "Epoch 224/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251852.3906\n",
      "Epoch 225/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251830.5781\n",
      "Epoch 226/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251809.0000\n",
      "Epoch 227/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251787.3594\n",
      "Epoch 228/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 251765.5781\n",
      "Epoch 229/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251743.9062\n",
      "Epoch 230/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251722.2812\n",
      "Epoch 231/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251700.6562\n",
      "Epoch 232/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251678.9062\n",
      "Epoch 233/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251657.2969\n",
      "Epoch 234/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251635.6406\n",
      "Epoch 235/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251613.9375\n",
      "Epoch 236/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251592.2969\n",
      "Epoch 237/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251570.5312\n",
      "Epoch 238/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251548.8281\n",
      "Epoch 239/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251527.2188\n",
      "Epoch 240/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251505.5156\n",
      "Epoch 241/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251483.8906\n",
      "Epoch 242/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251462.2656\n",
      "Epoch 243/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 251440.5469\n",
      "Epoch 244/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251418.9219\n",
      "Epoch 245/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251397.1875\n",
      "Epoch 246/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251375.5625\n",
      "Epoch 247/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251353.8438\n",
      "Epoch 248/250\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 251332.2969\n",
      "Epoch 249/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251310.6562\n",
      "Epoch 250/250\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251289.0312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a195e9270>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2147b5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [233211.390625,\n",
       "  233190.578125,\n",
       "  233169.78125,\n",
       "  233148.9375,\n",
       "  233128.09375,\n",
       "  233107.265625,\n",
       "  233086.40625,\n",
       "  233065.640625,\n",
       "  233044.796875,\n",
       "  233023.984375,\n",
       "  233003.109375,\n",
       "  232982.234375,\n",
       "  232961.484375,\n",
       "  232940.703125,\n",
       "  232919.84375,\n",
       "  232899.078125,\n",
       "  232878.1875,\n",
       "  232857.46875,\n",
       "  232836.59375,\n",
       "  232815.75,\n",
       "  232794.953125,\n",
       "  232774.1875,\n",
       "  232753.390625,\n",
       "  232732.609375,\n",
       "  232711.8125,\n",
       "  232690.96875,\n",
       "  232670.15625,\n",
       "  232649.28125,\n",
       "  232628.484375,\n",
       "  232607.6875,\n",
       "  232586.90625,\n",
       "  232566.078125,\n",
       "  232545.296875,\n",
       "  232524.4375,\n",
       "  232503.703125,\n",
       "  232482.953125,\n",
       "  232462.1875,\n",
       "  232441.328125,\n",
       "  232420.5,\n",
       "  232399.75,\n",
       "  232379.0,\n",
       "  232358.125,\n",
       "  232337.34375,\n",
       "  232316.59375,\n",
       "  232295.796875,\n",
       "  232275.046875,\n",
       "  232254.1875,\n",
       "  232233.390625,\n",
       "  232212.640625,\n",
       "  232191.90625,\n",
       "  232171.0625,\n",
       "  232150.328125,\n",
       "  232129.515625,\n",
       "  232108.703125,\n",
       "  232087.9375,\n",
       "  232067.15625,\n",
       "  232046.375,\n",
       "  232025.625,\n",
       "  232004.84375,\n",
       "  231984.046875,\n",
       "  231963.296875,\n",
       "  231942.515625,\n",
       "  231921.71875,\n",
       "  231900.953125,\n",
       "  231880.15625,\n",
       "  231859.390625,\n",
       "  231838.671875,\n",
       "  231817.875,\n",
       "  231797.09375,\n",
       "  231776.359375,\n",
       "  231755.59375,\n",
       "  231734.859375,\n",
       "  231714.109375,\n",
       "  231693.296875,\n",
       "  231672.53125,\n",
       "  231651.71875,\n",
       "  231631.0625,\n",
       "  231610.234375,\n",
       "  231589.515625,\n",
       "  231568.75,\n",
       "  231548.046875,\n",
       "  231527.265625,\n",
       "  231506.46875,\n",
       "  231485.671875,\n",
       "  231464.9375,\n",
       "  231444.3125,\n",
       "  231423.546875,\n",
       "  231402.75,\n",
       "  231381.96875,\n",
       "  231361.28125,\n",
       "  231340.5,\n",
       "  231319.71875,\n",
       "  231299.0,\n",
       "  231278.265625,\n",
       "  231257.53125,\n",
       "  231236.828125,\n",
       "  231216.09375,\n",
       "  231195.265625,\n",
       "  231174.515625,\n",
       "  231153.84375,\n",
       "  231133.125,\n",
       "  231112.390625,\n",
       "  231091.65625,\n",
       "  231070.921875,\n",
       "  231050.1875,\n",
       "  231029.484375,\n",
       "  231008.65625,\n",
       "  230987.984375,\n",
       "  230967.25,\n",
       "  230946.5625,\n",
       "  230925.78125,\n",
       "  230905.09375,\n",
       "  230884.390625,\n",
       "  230863.6875,\n",
       "  230842.921875,\n",
       "  230822.234375,\n",
       "  230801.46875,\n",
       "  230780.78125,\n",
       "  230760.09375,\n",
       "  230739.421875,\n",
       "  230718.671875,\n",
       "  230697.921875,\n",
       "  230677.1875,\n",
       "  230656.453125,\n",
       "  230635.6875,\n",
       "  230615.015625,\n",
       "  230594.40625,\n",
       "  230573.6875,\n",
       "  230552.921875,\n",
       "  230532.234375,\n",
       "  230511.5,\n",
       "  230490.8125,\n",
       "  230470.125,\n",
       "  230449.390625,\n",
       "  230428.703125,\n",
       "  230408.0,\n",
       "  230387.3125,\n",
       "  230366.65625,\n",
       "  230345.9375,\n",
       "  230325.234375,\n",
       "  230304.578125,\n",
       "  230283.8125,\n",
       "  230263.15625,\n",
       "  230242.46875,\n",
       "  230221.734375,\n",
       "  230201.078125,\n",
       "  230180.5,\n",
       "  230159.71875,\n",
       "  230138.96875,\n",
       "  230118.328125,\n",
       "  230097.671875,\n",
       "  230077.0,\n",
       "  230056.3125,\n",
       "  230035.59375,\n",
       "  230014.953125,\n",
       "  229994.15625,\n",
       "  229973.546875,\n",
       "  229952.984375,\n",
       "  229932.203125,\n",
       "  229911.5625,\n",
       "  229890.90625,\n",
       "  229870.21875,\n",
       "  229849.484375,\n",
       "  229828.84375,\n",
       "  229808.203125,\n",
       "  229787.46875,\n",
       "  229766.8125,\n",
       "  229746.21875,\n",
       "  229725.53125,\n",
       "  229704.796875,\n",
       "  229684.15625,\n",
       "  229663.546875,\n",
       "  229642.859375,\n",
       "  229622.125,\n",
       "  229601.484375,\n",
       "  229580.890625,\n",
       "  229560.203125,\n",
       "  229539.5,\n",
       "  229518.90625,\n",
       "  229498.234375,\n",
       "  229477.578125,\n",
       "  229456.875,\n",
       "  229436.1875,\n",
       "  229415.515625,\n",
       "  229394.90625,\n",
       "  229374.234375,\n",
       "  229353.546875,\n",
       "  229332.9375,\n",
       "  229312.203125,\n",
       "  229291.640625,\n",
       "  229270.96875,\n",
       "  229250.421875,\n",
       "  229229.765625,\n",
       "  229209.078125,\n",
       "  229188.484375,\n",
       "  229167.8125,\n",
       "  229147.21875,\n",
       "  229126.515625,\n",
       "  229105.84375,\n",
       "  229085.21875,\n",
       "  229064.640625,\n",
       "  229043.984375,\n",
       "  229023.34375,\n",
       "  229002.71875,\n",
       "  228982.078125,\n",
       "  228961.46875,\n",
       "  228940.828125,\n",
       "  228920.1875,\n",
       "  228899.5,\n",
       "  228878.828125,\n",
       "  228858.28125,\n",
       "  228837.6875,\n",
       "  228817.0,\n",
       "  228796.390625,\n",
       "  228775.6875,\n",
       "  228755.15625,\n",
       "  228734.5625,\n",
       "  228713.921875,\n",
       "  228693.328125,\n",
       "  228672.65625,\n",
       "  228651.984375,\n",
       "  228631.421875,\n",
       "  228610.78125,\n",
       "  228590.21875,\n",
       "  228569.59375,\n",
       "  228548.890625,\n",
       "  228528.296875,\n",
       "  228507.703125,\n",
       "  228487.078125,\n",
       "  228466.46875,\n",
       "  228445.890625,\n",
       "  228425.34375,\n",
       "  228404.734375,\n",
       "  228384.09375,\n",
       "  228363.421875,\n",
       "  228342.78125,\n",
       "  228322.265625,\n",
       "  228301.625,\n",
       "  228281.046875,\n",
       "  228260.359375,\n",
       "  228239.84375,\n",
       "  228219.25,\n",
       "  228198.75,\n",
       "  228178.109375,\n",
       "  228157.46875,\n",
       "  228136.921875,\n",
       "  228116.3125,\n",
       "  228095.640625,\n",
       "  228075.0,\n",
       "  228054.453125]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6366481b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[240561.515625,\n",
       " 240540.359375,\n",
       " 240519.3125,\n",
       " 240498.109375,\n",
       " 240476.921875,\n",
       " 240455.765625,\n",
       " 240434.625,\n",
       " 240413.46875,\n",
       " 240392.28125,\n",
       " 240371.125,\n",
       " 240349.96875,\n",
       " 240328.78125,\n",
       " 240307.59375,\n",
       " 240286.484375,\n",
       " 240265.34375,\n",
       " 240244.1875,\n",
       " 240222.953125,\n",
       " 240201.78125,\n",
       " 240180.59375,\n",
       " 240159.515625,\n",
       " 240138.421875,\n",
       " 240117.1875,\n",
       " 240096.046875,\n",
       " 240074.921875,\n",
       " 240053.8125,\n",
       " 240032.65625,\n",
       " 240011.515625,\n",
       " 239990.3125,\n",
       " 239969.234375,\n",
       " 239948.109375,\n",
       " 239926.875,\n",
       " 239905.765625,\n",
       " 239884.640625,\n",
       " 239863.515625,\n",
       " 239842.421875,\n",
       " 239821.140625,\n",
       " 239800.0625,\n",
       " 239779.0,\n",
       " 239757.78125,\n",
       " 239736.59375,\n",
       " 239715.453125,\n",
       " 239694.375,\n",
       " 239673.234375,\n",
       " 239652.0625,\n",
       " 239630.96875,\n",
       " 239609.84375,\n",
       " 239588.796875,\n",
       " 239567.609375,\n",
       " 239546.46875,\n",
       " 239525.390625,\n",
       " 239504.296875,\n",
       " 239483.203125,\n",
       " 239461.984375,\n",
       " 239440.9375,\n",
       " 239419.71875,\n",
       " 239398.578125,\n",
       " 239377.515625,\n",
       " 239356.390625,\n",
       " 239335.3125,\n",
       " 239314.21875,\n",
       " 239293.09375,\n",
       " 239271.953125,\n",
       " 239250.78125,\n",
       " 239229.734375,\n",
       " 239208.578125,\n",
       " 239187.5,\n",
       " 239166.421875,\n",
       " 239145.28125,\n",
       " 239124.1875,\n",
       " 239103.046875,\n",
       " 239082.015625,\n",
       " 239060.890625,\n",
       " 239039.796875,\n",
       " 239018.671875,\n",
       " 238997.640625,\n",
       " 238976.578125,\n",
       " 238955.453125,\n",
       " 238934.359375,\n",
       " 238913.21875,\n",
       " 238892.09375,\n",
       " 238871.0625,\n",
       " 238849.984375,\n",
       " 238828.921875,\n",
       " 238807.765625,\n",
       " 238786.703125,\n",
       " 238765.578125,\n",
       " 238744.453125,\n",
       " 238723.421875,\n",
       " 238702.3125,\n",
       " 238681.25,\n",
       " 238660.140625,\n",
       " 238639.046875,\n",
       " 238617.9375,\n",
       " 238596.9375,\n",
       " 238575.859375,\n",
       " 238554.765625,\n",
       " 238533.640625,\n",
       " 238512.5,\n",
       " 238491.515625,\n",
       " 238470.453125,\n",
       " 238449.34375,\n",
       " 238428.296875,\n",
       " 238407.21875,\n",
       " 238386.15625,\n",
       " 238365.09375,\n",
       " 238344.046875,\n",
       " 238322.921875,\n",
       " 238301.84375,\n",
       " 238280.78125,\n",
       " 238259.6875,\n",
       " 238238.65625,\n",
       " 238217.578125,\n",
       " 238196.59375,\n",
       " 238175.59375,\n",
       " 238154.453125,\n",
       " 238133.375,\n",
       " 238112.28125,\n",
       " 238091.25,\n",
       " 238070.171875,\n",
       " 238049.171875,\n",
       " 238028.09375,\n",
       " 238007.015625,\n",
       " 237985.96875,\n",
       " 237964.921875,\n",
       " 237943.90625,\n",
       " 237922.828125,\n",
       " 237901.84375,\n",
       " 237880.875,\n",
       " 237859.71875,\n",
       " 237838.703125,\n",
       " 237817.640625,\n",
       " 237796.578125,\n",
       " 237775.5,\n",
       " 237754.46875,\n",
       " 237733.421875,\n",
       " 237712.390625,\n",
       " 237691.390625,\n",
       " 237670.328125,\n",
       " 237649.234375,\n",
       " 237628.203125,\n",
       " 237607.203125,\n",
       " 237586.1875,\n",
       " 237565.140625,\n",
       " 237544.0625,\n",
       " 237523.109375,\n",
       " 237502.0625,\n",
       " 237481.0,\n",
       " 237459.9375,\n",
       " 237438.90625,\n",
       " 237417.96875,\n",
       " 237396.921875,\n",
       " 237375.90625,\n",
       " 237354.875,\n",
       " 237333.84375,\n",
       " 237312.875,\n",
       " 237291.84375,\n",
       " 237270.765625,\n",
       " 237249.734375,\n",
       " 237228.734375,\n",
       " 237207.75,\n",
       " 237186.703125,\n",
       " 237165.671875,\n",
       " 237144.640625,\n",
       " 237123.6875,\n",
       " 237102.703125,\n",
       " 237081.6875,\n",
       " 237060.65625,\n",
       " 237039.703125,\n",
       " 237018.71875,\n",
       " 236997.640625,\n",
       " 236976.640625,\n",
       " 236955.703125,\n",
       " 236934.625,\n",
       " 236913.578125,\n",
       " 236892.59375,\n",
       " 236871.609375,\n",
       " 236850.65625,\n",
       " 236829.71875,\n",
       " 236808.6875,\n",
       " 236787.703125,\n",
       " 236766.625,\n",
       " 236745.671875,\n",
       " 236724.65625,\n",
       " 236703.65625,\n",
       " 236682.65625,\n",
       " 236661.640625,\n",
       " 236640.609375,\n",
       " 236619.6875,\n",
       " 236598.671875,\n",
       " 236577.671875,\n",
       " 236556.6875,\n",
       " 236535.71875,\n",
       " 236514.703125,\n",
       " 236493.71875,\n",
       " 236472.796875,\n",
       " 236451.796875,\n",
       " 236430.8125,\n",
       " 236409.84375,\n",
       " 236388.890625,\n",
       " 236367.9375,\n",
       " 236346.859375,\n",
       " 236325.96875,\n",
       " 236304.9375,\n",
       " 236283.890625,\n",
       " 236263.0,\n",
       " 236242.0625,\n",
       " 236221.125,\n",
       " 236200.0625,\n",
       " 236179.125,\n",
       " 236158.1875,\n",
       " 236137.21875,\n",
       " 236116.25,\n",
       " 236095.21875,\n",
       " 236074.328125,\n",
       " 236053.375,\n",
       " 236032.390625,\n",
       " 236011.46875,\n",
       " 235990.53125,\n",
       " 235969.53125,\n",
       " 235948.578125,\n",
       " 235927.640625,\n",
       " 235906.671875,\n",
       " 235885.71875,\n",
       " 235864.703125,\n",
       " 235843.75,\n",
       " 235822.828125,\n",
       " 235801.921875,\n",
       " 235780.953125,\n",
       " 235759.953125,\n",
       " 235739.015625,\n",
       " 235718.03125,\n",
       " 235697.078125,\n",
       " 235676.203125,\n",
       " 235655.21875,\n",
       " 235634.3125,\n",
       " 235613.375,\n",
       " 235592.40625,\n",
       " 235571.453125,\n",
       " 235550.515625,\n",
       " 235529.59375,\n",
       " 235508.65625,\n",
       " 235487.703125,\n",
       " 235466.78125,\n",
       " 235445.828125,\n",
       " 235424.875,\n",
       " 235404.0,\n",
       " 235383.046875,\n",
       " 235362.15625,\n",
       " 235341.171875,\n",
       " 235320.25]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model.history.history['loss']\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a24fa240",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = model.evaluate(X_train,y_train,verbose=0)\n",
    "test_score = model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "66d78154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251277.625"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "57f0e7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "69819715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594],\n",
       "       [5.50594]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1efa1a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "44f0d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df1=pd.DataFrame(data=y_test,columns=['y-test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "899e5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df2=pd.DataFrame(data=test_predictions,columns=['test_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "845df443",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.concat([pred_df1,pred_df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8fbc4bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y-test</th>\n",
       "      <th>test_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>402.296319</td>\n",
       "      <td>5.50594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624.156198</td>\n",
       "      <td>5.50594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>582.455066</td>\n",
       "      <td>5.50594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>578.588606</td>\n",
       "      <td>5.50594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371.224104</td>\n",
       "      <td>5.50594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>525.704657</td>\n",
       "      <td>5.50594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>502.909473</td>\n",
       "      <td>5.50594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>612.727910</td>\n",
       "      <td>5.50594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>417.569725</td>\n",
       "      <td>5.50594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>410.538250</td>\n",
       "      <td>5.50594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         y-test  test_predictions\n",
       "0    402.296319           5.50594\n",
       "1    624.156198           5.50594\n",
       "2    582.455066           5.50594\n",
       "3    578.588606           5.50594\n",
       "4    371.224104           5.50594\n",
       "..          ...               ...\n",
       "295  525.704657           5.50594\n",
       "296  502.909473           5.50594\n",
       "297  612.727910           5.50594\n",
       "298  417.569725           5.50594\n",
       "299  410.538250           5.50594\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c0664c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "35a5f448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494.86939951460334"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(result['y-test'],result['test_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2be36bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=[[950,1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fce3fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=scaler.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cfe1d055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.50594]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4797c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bf983496",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('new_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "237148ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "later_model = load_model('new_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "247a633d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.50594]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "later_model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d446615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
